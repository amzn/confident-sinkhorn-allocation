{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "reproduce_experiments_Confident_Sinkhorn_Allocation.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyMtegCO4Y3RIIC3kNxlOOIp",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ntienvu/confident_sinkhorn_allocation/blob/master/reproduce_experiments_Confident_Sinkhorn_Allocation.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tubZzNQc3EFg",
        "outputId": "0824b5a1-03d4-48ab-9f12-f356564d4c42"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting git+https://ntienvu:****@github.com/ntienvu/confident_sinkhorn_allocation\n",
            "  Cloning https://ntienvu:****@github.com/ntienvu/confident_sinkhorn_allocation to /tmp/pip-req-build-lo7w5bdx\n",
            "  Running command git clone -q 'https://ntienvu:****@github.com/ntienvu/confident_sinkhorn_allocation' /tmp/pip-req-build-lo7w5bdx\n",
            "Collecting colorama>=0.4.5\n",
            "  Using cached colorama-0.4.5-py2.py3-none-any.whl (16 kB)\n",
            "Collecting cycler>=0.11.0\n",
            "  Using cached cycler-0.11.0-py3-none-any.whl (6.4 kB)\n",
            "Collecting fonttools>=4.33.3\n",
            "  Using cached fonttools-4.34.2-py3-none-any.whl (944 kB)\n",
            "Collecting joblib>=1.1.0\n",
            "  Using cached joblib-1.1.0-py2.py3-none-any.whl (306 kB)\n",
            "Collecting kiwisolver>=1.4.3\n",
            "  Using cached kiwisolver-1.4.3-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.whl (1.1 MB)\n",
            "Collecting matplotlib>=3.1.2\n",
            "  Using cached matplotlib-3.5.2-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.whl (11.2 MB)\n"
          ]
        }
      ],
      "source": [
        "!pip install --upgrade --force-reinstall git+https://ntienvu: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@github.com/ntienvu/confident_sinkhorn_allocation"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://ntienvu: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@github.com/ntienvu/confident_sinkhorn_allocation\n"
      ],
      "metadata": {
        "id": "wWqPgmS_M0s9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import os\n",
        "import argparse\n",
        "import logging\n",
        "import pickle\n",
        "from tqdm import tqdm\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from algorithm.pseudo_labeling import Pseudo_Labeling\n",
        "from algorithm.flexmatch import FlexMatch\n",
        "from algorithm.ups import UPS\n",
        "from algorithm.csa import CSA\n",
        "from xgboost import XGBClassifier\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "from utilities.utils import get_train_test_unlabeled,append_acc_early_termination\n",
        "from utilities.utils import get_train_test_unlabeled_for_multilabel_classification\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ],
      "metadata": {
        "id": "HkUXA22N3Oj1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# We run the experiments using 10 repeated trials (in the paper we run over 30 trials)\n",
        "# We compare the results with 5 baselines: Supervised learning, Pseudo-labeling, FlexMatch, UPS, SLA and CSA\n",
        "# There are multiple datasets, we pick three of them for this report."
      ],
      "metadata": {
        "id": "fE9mhjas4cQP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Specify hyperparameters"
      ],
      "metadata": {
        "id": "N0ZtejZ74chA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "numTrials=10\n",
        "numIters=5\n",
        "confidence_choice='ttest'\n",
        "num_XGB_models=10\n",
        "upper_threshold=0.8\n",
        "lower_threshold=0.2 # for UPS\n",
        "dataset_list=['analcatdata_authorship','dna_no','madelon_no','digits']\n",
        "algorithm_list=['supervised_learning','Pseudo_Labeling','FlexMatch','UPS','SLA','CSA']\n",
        "\n",
        "path_to_file='confident_sinkhorn_allocation/all_data.pickle'\n"
      ],
      "metadata": {
        "id": "iVk2Ugdx-0Ol"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def supervised_learning(x_train, y_train, x_test, y_test):\n",
        "  param = {}\n",
        "  param['booster'] = 'gbtree'\n",
        "  param['objective'] = 'binary:logistic'\n",
        "  param['verbosity'] = 0\n",
        "  param['silent'] = 1\n",
        "  param['seed'] = 0\n",
        "\n",
        "  # create XGBoost instance with default hyper-parameters\n",
        "  xgb=XGBClassifier(**param,use_label_encoder=False)\n",
        "\n",
        "  xgb.fit(x_train, y_train)\n",
        "\n",
        "  # evaluate the performance on the test set\n",
        "  y_test_pred = xgb.predict(x_test)      \n",
        "  supervised_learning_accuracy= np.round( accuracy_score(y_test_pred, y_test)*100, 2)# round to 2 digits xx.yy %\n",
        "  return supervised_learning_accuracy"
      ],
      "metadata": {
        "id": "XCIZlW5rCDXm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# a wrapper function to plot the comparison\n",
        "\n",
        "def get_mean_std(Accuracy_Matrix):\n",
        "  \"\"\"\n",
        "  Args:\n",
        "    Accuracy_Matrix: [nRepeats x nIterations]\n",
        "  Out:\n",
        "    mean [1 x nIterations]\n",
        "    std  [1 x nIterations]\n",
        "  \"\"\"\n",
        "  return np.mean(Accuracy_Matrix,axis=0),np.std(Accuracy_Matrix,axis=0)\n",
        "\n",
        "def plot_result_comparison(numIters,Accuracy_Supervised_Learning,Accuracy_Pseudo_Labeling,\\\n",
        "                        Accuracy_FlexMatch,Accuracy_UPS,Accuracy_SLA, Accuracy_CSA,  dataset_name):\n",
        "\n",
        "  numIters=5\n",
        "  plt.figure(figsize=(8,5))\n",
        "\n",
        "  # Supervised Learning\n",
        "  mean=np.mean(Accuracy_Supervised_Learning)\n",
        "  std=np.std(Accuracy_Supervised_Learning)\n",
        "  mean=[mean]*(numIters+1)\n",
        "  std=np.asarray([std]*(numIters+1))\n",
        "  plt.errorbar(np.arange(numIters+1),mean,yerr=0.1*std,fmt='m:',linewidth=4,label=\"Supervised Learning\") \n",
        "\n",
        "  # Pseudo Labeling\n",
        "  mean,std=get_mean_std(Accuracy_Pseudo_Labeling)\n",
        "  plt.errorbar(np.arange(numIters+1),mean,yerr=0.1*std,fmt='k-.',linewidth=4,label='Pseudo-labeling')\n",
        "\n",
        "  # FlexMatch\n",
        "  mean,std=get_mean_std(Accuracy_FlexMatch)\n",
        "  plt.errorbar(np.arange(numIters+1),mean,yerr=0.1*std,fmt='g--*',linewidth=4,label='FlexMatch')\n",
        "\n",
        "  # UPS\n",
        "  mean,std=get_mean_std(Accuracy_UPS)\n",
        "  plt.errorbar(np.arange(numIters+1),mean,yerr=0.1*std,fmt='c:v',linewidth=4,label='UPS')\n",
        "\n",
        "  # SLA\n",
        "  mean,std=get_mean_std(Accuracy_SLA)\n",
        "  plt.errorbar(np.arange(numIters+1),mean,yerr=0.1*std,fmt='b:s',linewidth=4,label='SLA')\n",
        "\n",
        "  # CSA\n",
        "  mean,std=get_mean_std(Accuracy_CSA)\n",
        "  plt.errorbar(np.arange(numIters+1),mean,yerr=0.1*std,fmt='r-s',linewidth=4,label='CSA')\n",
        "\n",
        "  plt.xlabel(\"Pseudo-labeling Iteration\",fontsize=14)\n",
        "  plt.ylabel(\"Test Accuracy\",fontsize=14)\n",
        "\n",
        "  plt.legend(fontsize=12,ncol=3)\n",
        "\n",
        "  plt.title(\"Dataset = \" + dataset_name,fontsize=14 )\n",
        "\n",
        "\n",
        "def run_algorithm(dataset_name,path_to_file, algorithm_name):\n",
        "\n",
        "  Accuracy_list=[]\n",
        "  for tt in tqdm(range(numTrials)):\n",
        "    np.random.seed(tt)\n",
        "    \n",
        "    # load the data for multiclassification\n",
        "    x_train,y_train, x_test, y_test, x_unlabeled=get_train_test_unlabeled(dataset_name,path_to_file,random_state=tt)\n",
        "\n",
        "    # train the model and get the accuracy\n",
        "    if algorithm_name==\"Pseudo_Labeling\":\n",
        "      pseudo_labeller = Pseudo_Labeling(x_unlabeled,x_test,y_test, \n",
        "                  num_iters=numIters, upper_threshold=upper_threshold,verbose = 0)\n",
        "    elif algorithm_name==\"FlexMatch\":\n",
        "      pseudo_labeller = FlexMatch(x_unlabeled,x_test,y_test, \n",
        "                num_iters=numIters,upper_threshold=upper_threshold,verbose = 0)\n",
        "    elif algorithm_name==\"UPS\":\n",
        "      pseudo_labeller = UPS(x_unlabeled,x_test,y_test, \n",
        "                num_iters=numIters,\n",
        "                upper_threshold=upper_threshold,\n",
        "                lower_threshold=lower_threshold,\n",
        "                num_XGB_models=num_XGB_models,verbose = 0)\n",
        "    elif algorithm_name==\"SLA\":\n",
        "      pseudo_labeller = CSA(x_unlabeled,x_test,y_test, \n",
        "                num_iters=numIters,\n",
        "                confidence_choice=None,# when setting confidence_choice=None => this is equivalent to SLA \n",
        "                num_XGB_models=num_XGB_models,verbose = 0)\n",
        "    elif algorithm_name==\"CSA\":\n",
        "      pseudo_labeller = CSA(x_unlabeled,x_test,y_test, \n",
        "                num_iters=numIters,\n",
        "                confidence_choice='ttest',\n",
        "                num_XGB_models=num_XGB_models,verbose = 0)\n",
        "\n",
        "    pseudo_labeller.fit(x_train, y_train)\n",
        "\n",
        "    #  append_acc_early_termination: if early termination happens, this function will copy the result to be in the same dimension\n",
        "\n",
        "    Accuracy_list.append( append_acc_early_termination(pseudo_labeller.test_acc,numIters) )\n",
        "\n",
        "    return Accuracy_list\n",
        "    "
      ],
      "metadata": {
        "id": "efMR8vCrtk1B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset_name='analcatdata_authorship'\n",
        "\n",
        "# Supervised learning==========================================================\n",
        "Accuracy_Supervised_Learning=[]\n",
        "for tt in tqdm(range(numTrials)):\n",
        "  np.random.seed(tt)\n",
        "  \n",
        "  # load the data for multiclassification\n",
        "  x_train,y_train, x_test, y_test, x_unlabeled=get_train_test_unlabeled(dataset_name,path_to_file,random_state=tt)\n",
        "\n",
        "  # train the model and get the accuracy\n",
        "  accuracy=supervised_learning(x_train, y_train, x_test, y_test)\n",
        "  Accuracy_Supervised_Learning.append(accuracy)\n",
        "\n",
        "# Pseudo-labeling==============================================================\n",
        "Accuracy_Pseudo_Labeling=run_algorithm(dataset_name,path_to_file, algorithm_name=\"Pseudo_Labeling\")\n",
        "\n",
        "# FlexMatch====================================================================\n",
        "Accuracy_FlexMatch=Accuracy_Pseudo_Labeling=run_algorithm(dataset_name,path_to_file, algorithm_name=\"FlexMatch\")\n",
        "\n",
        "# UPS====================================================================\n",
        "Accuracy_UPS=Accuracy_Pseudo_Labeling=run_algorithm(dataset_name,path_to_file, algorithm_name=\"UPS\")\n",
        "\n",
        "# SLA====================================================================\n",
        "Accuracy_SLA=Accuracy_Pseudo_Labeling=run_algorithm(dataset_name,path_to_file, algorithm_name=\"SLA\")\n",
        "\n",
        "# CSA====================================================================\n",
        "Accuracy_CSA=Accuracy_Pseudo_Labeling=run_algorithm(dataset_name,path_to_file, algorithm_name=\"CSA\")\n",
        "     \n",
        "\n"
      ],
      "metadata": {
        "id": "PnWZENzL4cop"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#!python -m pip uninstall matplotlib\n",
        "#!pip install matplotlib==3.1.3\n",
        "\n",
        "# Plot the performance\n",
        "\n",
        "plot_result_comparison(numIters,Accuracy_Supervised_Learning,Accuracy_Pseudo_Labeling,\\\n",
        "                        Accuracy_FlexMatch,Accuracy_UPS,Accuracy_SLA, Accuracy_CSA,  dataset_name)"
      ],
      "metadata": {
        "id": "JtduXoXpSHzm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset_name='dna_no'\n",
        "\n",
        "# Supervised learning==========================================================\n",
        "Accuracy_Supervised_Learning=[]\n",
        "for tt in tqdm(range(numTrials)):\n",
        "  np.random.seed(tt)\n",
        "  \n",
        "  # load the data for multiclassification\n",
        "  x_train,y_train, x_test, y_test, x_unlabeled=get_train_test_unlabeled(dataset_name,path_to_file,random_state=tt)\n",
        "\n",
        "  # train the model and get the accuracy\n",
        "  accuracy=supervised_learning(x_train, y_train, x_test, y_test)\n",
        "  Accuracy_Supervised_Learning.append(accuracy)\n",
        "\n",
        "\n",
        "# Pseudo-labeling==============================================================\n",
        "Accuracy_Pseudo_Labeling=[]\n",
        "for tt in tqdm(range(numTrials)):\n",
        "  np.random.seed(tt)\n",
        "  \n",
        "  # load the data for multiclassification\n",
        "  x_train,y_train, x_test, y_test, x_unlabeled=get_train_test_unlabeled(dataset_name,path_to_file,random_state=tt)\n",
        "\n",
        "  # train the model and get the accuracy\n",
        "  pseudo_labeller = Pseudo_Labeling(x_unlabeled,x_test,y_test, \n",
        "                num_iters=numIters, upper_threshold=upper_threshold,verbose = 0)\n",
        "  pseudo_labeller.fit(x_train, y_train)\n",
        "  Accuracy_Pseudo_Labeling.append( append_acc_early_termination(pseudo_labeller.test_acc,numIters) )\n",
        "  # append_acc_early_termination: if early termination happens, this function will copy the result to be in the same dimension\n",
        "\n",
        "\n",
        "# FlexMatch====================================================================\n",
        "Accuracy_FlexMatch=[]\n",
        "for tt in tqdm(range(numTrials)):\n",
        "  np.random.seed(tt)\n",
        "  \n",
        "  # load the data for multiclassification\n",
        "  x_train,y_train, x_test, y_test, x_unlabeled=get_train_test_unlabeled(dataset_name,path_to_file,random_state=tt)\n",
        "\n",
        "  # train the model and get the accuracy\n",
        "  pseudo_labeller = FlexMatch(x_unlabeled,x_test,y_test, \n",
        "                num_iters=numIters,upper_threshold=upper_threshold,verbose = 0)\n",
        "  pseudo_labeller.fit(x_train, y_train)\n",
        "  Accuracy_FlexMatch.append( append_acc_early_termination(pseudo_labeller.test_acc,numIters) )\n",
        "\n",
        "\n",
        "# UPS====================================================================\n",
        "Accuracy_UPS=[]\n",
        "for tt in tqdm(range(numTrials)):\n",
        "  np.random.seed(tt)\n",
        "  \n",
        "  # load the data for multiclassification\n",
        "  x_train,y_train, x_test, y_test, x_unlabeled=get_train_test_unlabeled(dataset_name,path_to_file,random_state=tt)\n",
        "\n",
        "  # train the model and get the accuracy\n",
        "  pseudo_labeller = UPS(x_unlabeled,x_test,y_test, \n",
        "                num_iters=numIters,\n",
        "                upper_threshold=upper_threshold,\n",
        "                lower_threshold=lower_threshold,\n",
        "                num_XGB_models=num_XGB_models,verbose = 0)\n",
        "  pseudo_labeller.fit(x_train, y_train)\n",
        "  Accuracy_UPS.append( append_acc_early_termination(pseudo_labeller.test_acc,numIters) )\n",
        "\n",
        "\n",
        "\n",
        "# SLA====================================================================\n",
        "Accuracy_SLA=[]\n",
        "for tt in tqdm(range(numTrials)):\n",
        "  np.random.seed(tt)\n",
        "  \n",
        "  # load the data for multiclassification\n",
        "  x_train,y_train, x_test, y_test, x_unlabeled=get_train_test_unlabeled(dataset_name,path_to_file,random_state=tt)\n",
        "\n",
        "  # train the model and get the accuracy\n",
        "  pseudo_labeller = CSA(x_unlabeled,x_test,y_test, \n",
        "                num_iters=numIters,\n",
        "                confidence_choice=None,# when setting confidence_choice=None => this is equivalent to SLA \n",
        "                num_XGB_models=num_XGB_models,verbose = 0)\n",
        "  pseudo_labeller.fit(x_train, y_train)\n",
        "  Accuracy_SLA.append( append_acc_early_termination(pseudo_labeller.test_acc,numIters) )\n",
        "\n",
        "\n",
        "# CSA====================================================================\n",
        "Accuracy_CSA=[]\n",
        "for tt in tqdm(range(numTrials)):\n",
        "  np.random.seed(tt)\n",
        "  \n",
        "  # load the data for multiclassification\n",
        "  x_train,y_train, x_test, y_test, x_unlabeled=get_train_test_unlabeled(dataset_name,path_to_file,random_state=tt)\n",
        "\n",
        "  # train the model and get the accuracy\n",
        "  pseudo_labeller = CSA(x_unlabeled,x_test,y_test, \n",
        "                num_iters=numIters,\n",
        "                confidence_choice='ttest',\n",
        "                num_XGB_models=num_XGB_models,verbose = 1)\n",
        "  pseudo_labeller.fit(x_train, y_train)\n",
        "  Accuracy_CSA.append( append_acc_early_termination(pseudo_labeller.test_acc,numIters) )"
      ],
      "metadata": {
        "id": "kWuGRIBJ9SpK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#!python -m pip uninstall matplotlib\n",
        "#!pip install matplotlib==3.1.3\n",
        "plot_result_comparison(numIters,Accuracy_Supervised_Learning,Accuracy_Pseudo_Labeling,\\\n",
        "                        Accuracy_FlexMatch,Accuracy_UPS,Accuracy_SLA, Accuracy_CSA,  dataset_name)\n",
        "\n"
      ],
      "metadata": {
        "id": "u49Cjlg6-SXR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset_name='madelon_no'\n",
        "\n",
        "# Supervised learning==========================================================\n",
        "Accuracy_Supervised_Learning=[]\n",
        "for tt in tqdm(range(numTrials)):\n",
        "  np.random.seed(tt)\n",
        "  \n",
        "  # load the data for multiclassification\n",
        "  x_train,y_train, x_test, y_test, x_unlabeled=get_train_test_unlabeled(dataset_name,path_to_file,random_state=tt)\n",
        "\n",
        "  # train the model and get the accuracy\n",
        "  accuracy=supervised_learning(x_train, y_train, x_test, y_test)\n",
        "  Accuracy_Supervised_Learning.append(accuracy)\n",
        "\n",
        "\n",
        "# Pseudo-labeling==============================================================\n",
        "Accuracy_Pseudo_Labeling=[]\n",
        "for tt in tqdm(range(numTrials)):\n",
        "  np.random.seed(tt)\n",
        "  \n",
        "  # load the data for multiclassification\n",
        "  x_train,y_train, x_test, y_test, x_unlabeled=get_train_test_unlabeled(dataset_name,path_to_file,random_state=tt)\n",
        "\n",
        "  # train the model and get the accuracy\n",
        "  pseudo_labeller = Pseudo_Labeling(x_unlabeled,x_test,y_test, \n",
        "                num_iters=numIters, upper_threshold=upper_threshold,verbose = 0)\n",
        "  pseudo_labeller.fit(x_train, y_train)\n",
        "  Accuracy_Pseudo_Labeling.append( append_acc_early_termination(pseudo_labeller.test_acc,numIters) )\n",
        "  # append_acc_early_termination: if early termination happens, this function will copy the result to be in the same dimension\n",
        "\n",
        "\n",
        "# FlexMatch====================================================================\n",
        "Accuracy_FlexMatch=[]\n",
        "for tt in tqdm(range(numTrials)):\n",
        "  np.random.seed(tt)\n",
        "  \n",
        "  # load the data for multiclassification\n",
        "  x_train,y_train, x_test, y_test, x_unlabeled=get_train_test_unlabeled(dataset_name,path_to_file,random_state=tt)\n",
        "\n",
        "  # train the model and get the accuracy\n",
        "  pseudo_labeller = FlexMatch(x_unlabeled,x_test,y_test, \n",
        "                num_iters=numIters,upper_threshold=upper_threshold,verbose = 0)\n",
        "  pseudo_labeller.fit(x_train, y_train)\n",
        "  Accuracy_FlexMatch.append( append_acc_early_termination(pseudo_labeller.test_acc,numIters) )\n",
        "\n",
        "\n",
        "# UPS====================================================================\n",
        "Accuracy_UPS=[]\n",
        "for tt in tqdm(range(numTrials)):\n",
        "  np.random.seed(tt)\n",
        "  \n",
        "  # load the data for multiclassification\n",
        "  x_train,y_train, x_test, y_test, x_unlabeled=get_train_test_unlabeled(dataset_name,path_to_file,random_state=tt)\n",
        "\n",
        "  # train the model and get the accuracy\n",
        "  pseudo_labeller = UPS(x_unlabeled,x_test,y_test, \n",
        "                num_iters=numIters,\n",
        "                upper_threshold=upper_threshold,\n",
        "                lower_threshold=lower_threshold,\n",
        "                num_XGB_models=num_XGB_models,verbose = 0)\n",
        "  pseudo_labeller.fit(x_train, y_train)\n",
        "  Accuracy_UPS.append( append_acc_early_termination(pseudo_labeller.test_acc,numIters) )\n",
        "\n",
        "\n",
        "\n",
        "# SLA====================================================================\n",
        "Accuracy_SLA=[]\n",
        "for tt in tqdm(range(numTrials)):\n",
        "  np.random.seed(tt)\n",
        "  \n",
        "  # load the data for multiclassification\n",
        "  x_train,y_train, x_test, y_test, x_unlabeled=get_train_test_unlabeled(dataset_name,path_to_file,random_state=tt)\n",
        "\n",
        "  # train the model and get the accuracy\n",
        "  pseudo_labeller = CSA(x_unlabeled,x_test,y_test, \n",
        "                num_iters=numIters,\n",
        "                confidence_choice=None,# when setting confidence_choice=None => this is equivalent to SLA \n",
        "                num_XGB_models=num_XGB_models,verbose = 0)\n",
        "  pseudo_labeller.fit(x_train, y_train)\n",
        "  Accuracy_SLA.append( append_acc_early_termination(pseudo_labeller.test_acc,numIters) )\n",
        "\n",
        "\n",
        "# CSA====================================================================\n",
        "Accuracy_CSA=[]\n",
        "for tt in tqdm(range(numTrials)):\n",
        "  np.random.seed(tt)\n",
        "  \n",
        "  # load the data for multiclassification\n",
        "  x_train,y_train, x_test, y_test, x_unlabeled=get_train_test_unlabeled(dataset_name,path_to_file,random_state=tt)\n",
        "\n",
        "  # train the model and get the accuracy\n",
        "  pseudo_labeller = CSA(x_unlabeled,x_test,y_test, \n",
        "                num_iters=numIters,\n",
        "                confidence_choice='ttest',\n",
        "                num_XGB_models=num_XGB_models,verbose = 0)\n",
        "  pseudo_labeller.fit(x_train, y_train)\n",
        "  Accuracy_CSA.append( append_acc_early_termination(pseudo_labeller.test_acc,numIters) )"
      ],
      "metadata": {
        "id": "t47luIMmcDiV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plot_result_comparison(numIters,Accuracy_Supervised_Learning,Accuracy_Pseudo_Labeling,\\\n",
        "                        Accuracy_FlexMatch,Accuracy_UPS,Accuracy_SLA, Accuracy_CSA,  dataset_name)"
      ],
      "metadata": {
        "id": "pMEHQlQycEWy"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}